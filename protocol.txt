Du:
# Prompt Series  
**Project:** Excel Product Calculator → Python Product Calculator  

---

## GLOBAL CONTEXT

### Role and Objective  
You are a **Senior Python Engineer**.  
Goal: From the Excel file `Tariff_Calculator.xlsm`, create a **modular, pure‑Python product calculator** that produces identical results.  
The solution consists of **seven scripts** and several **.csv input files** (see table below).  
Your working directory is root.  
The Excel file is located in the `input` directory.  
All outputs generated by the LLM and by the scripts must be written to the project root directory.  


### Deliverables
| Code | File | Content | Acceptance Criteria |
|--------|-------|--------|---------------|
| EXCEL_TO_TEXT | `excel_to_text.py` | Extract cells & ranges → `excelcell.csv`, `excelrange.csv` | Both CSVs exist & have ≥ 1 row |
| VBA_TO_TEXT | `vba_to_text.py` | Extract all VBA modules → `Mod_*.txt` | All module files exist |
| DATA_EXTRACT | `data_extract.py` | Create `var.csv`, `tariff.csv`, `limits.csv`, `tables.csv`, `tariff.py` | All files exist & have ≥ 1 data row |
| BASISFUNCT | `basfunct.py` | 1‑to‑1 port of the VBA base functions | pytest suite passes |
| AUSFUNCT | `outfunc.py` | Contains `NormGrossAnnualPrem()` and dependent functions and other similar premium functions | `NormGrossAnnualPrem()` test < 1 e‑6 deviation |
| CLI_RUNNER | `run_calc.py` | Command‑line interface | `python run_calc.py --help` runs |

### General Rules  
- **Language:** English in documentation, variable names in English (`present_value`).  
- **Quality:** Black formatting, Ruff lint = 0 warnings.  
- **Response format:** Each task delivers as many executable code blocks as defined in the relevant task.  
- **Progress:** Work **strictly step by step**. Complete each task, wait for my **“✅”**, only then continue. DO NOT START any coding if note explicitely instructed to!  

ChatGPT:
Understood. I’ll work step-by-step, produce exactly one executable code block per task, write all generated outputs to /Bartek project root, and not start any coding until you explicitly tell me to.

When you’re ready, tell me which deliverable to start with (recommended order is EXCEL_TO_TEXT → VBA_TO_TEXT → DATA_EXTRACT → basfunct → outfunc → outfunc2 → run_calc).


Du:
## TASK 1 – Implement Code for Context Export (Excel → CSV)

1. **Goal**: Create a simple script to tranlsate Excel-Content in text (`excel_to_text.py`)
2. **Input for the script**: `Tariff_Calculator.xlsm`  
3. **Output fo the script**  
   - `excelcell.csv` (columns: Sheet, Address, Formula, Value)  
   - `excelrange.csv` (columns: Sheet, Name, Address)  
4. **Procedure for the script**  
   - Use `xlwings` for array formulas.  
   - Ignore empty cells.  
   - Prerequisite: `xlwings` requires a local Excel installation.  
5. **Success Check**  
```python
assert Path("excelcell.csv").stat().st_size > 10_000
assert "Calculation" in pd.read_csv("excelcell.csv")["Sheet"].unique()
```  
6. **Delivery format**: Full, executable code block.

ChatGPT:
#!/usr/bin/env python3
"""
EXCEL_TO_TEXT: Export Excel workbook content to CSV.

Input:
  input/Tariff_Calculator.xlsm

Outputs (written to project root / current working directory):
  - excelcell.csv  columns: Sheet, Address, Formula, Value
  - excelrange.csv columns: Sheet, Name, Address

Notes:
  - Uses xlwings (requires local Excel installation).
  - Ignores empty cells (both formula and value empty/None).
"""

from __future__ import annotations

import csv
import json
import re
from pathlib import Path
from typing import Any, Iterable, Optional, Tuple

import xlwings as xw


INPUT_PATH = Path("input") / "Tariff_Calculator.xlsm"
OUT_CELLS = Path("excelcell.csv")
OUT_RANGES = Path("excelrange.csv")


def col_to_letters(col_num: int) -> str:
    """1 -> A, 26 -> Z, 27 -> AA"""
    if col_num < 1:
        raise ValueError(f"Invalid column number: {col_num}")
    letters = []
    while col_num:
        col_num, rem = divmod(col_num - 1, 26)
        letters.append(chr(65 + rem))
    return "".join(reversed(letters))


def a1_address(row: int, col: int) -> str:
    return f"{col_to_letters(col)}{row}"


def stringify_value(v: Any) -> str:
    if v is None:
        return ""
    # Excel errors sometimes come through as strings like '#N/A', keep as-is
    if isinstance(v, (str, int, float, bool)):
        return str(v)
    # Datetimes, arrays, etc.
    try:
        return json.dumps(v, ensure_ascii=False, default=str)
    except TypeError:
        return str(v)


def normalize_formula(f: Any) -> str:
    if f is None:
        return ""
    if isinstance(f, str):
        return f
    # xlwings can return nested lists for multi-area; serialize to JSON for safety
    try:
        return json.dumps(f, ensure_ascii=False, default=str)
    except TypeError:
        return str(f)


_REFERS_TO_SHEET_RE = re.compile(
    r"""^=?'?(?P<sheet>[^']+?)'?!""", re.IGNORECASE
)


def parse_sheet_from_refers_to(refers_to: str) -> str:
    """
    Try to extract the sheet name from a Name.RefersTo string like:
      ="'Calculation'!$A$1:$B$2"
      ="=Calculation!$A$1"
    """
    if not refers_to:
        return ""
    s = refers_to.strip()
    if s.startswith("="):
        s = s[1:].lstrip()
    m = _REFERS_TO_SHEET_RE.match(s)
    return m.group("sheet") if m else ""


def is_empty_cell(formula: str, value: Any) -> bool:
    # Treat as empty if no formula and value is None/"".
    if formula and formula != "":
        return False
    if value is None:
        return True
    if isinstance(value, str) and value.strip() == "":
        return True
    return False


def iter_used_range_cells(
    sheet: xw.Sheet,
) -> Iterable[Tuple[str, str, str, Any]]:
    """
    Yield (sheet_name, address, formula, value) for non-empty cells in sheet.used_range.
    Uses array reads for performance and to preserve array formulas via Excel.
    """
    used = sheet.used_range
    # If the sheet is truly empty, used_range may still return A1; we will filter empties.
    top_row = used.row
    left_col = used.column
    nrows = used.rows.count
    ncols = used.columns.count

    # Read formulas & values as 2D arrays in a single call each
    formulas = used.formula  # can be scalar if single cell
    values = used.value

    # Normalize to 2D lists
    if nrows == 1 and ncols == 1:
        formulas_2d = [[formulas]]
        values_2d = [[values]]
    else:
        # xlwings returns list-of-lists for ranges; ensure shape
        formulas_2d = formulas
        values_2d = values

    for r in range(nrows):
        row_idx = top_row + r
        for c in range(ncols):
            col_idx = left_col + c
            f = normalize_formula(formulas_2d[r][c])
            v = values_2d[r][c]
            if is_empty_cell(f, v):
                continue
            addr = a1_address(row_idx, col_idx)
            yield (sheet.name, addr, f, v)


def export_cells(book: xw.Book) -> int:
    count = 0
    with OUT_CELLS.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["Sheet", "Address", "Formula", "Value"])
        for sht in book.sheets:
            for sheet_name, addr, formula, value in iter_used_range_cells(sht):
                w.writerow([sheet_name, addr, formula, stringify_value(value)])
                count += 1
    return count


def export_named_ranges(book: xw.Book) -> int:
    count = 0
    with OUT_RANGES.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["Sheet", "Name", "Address"])
        for nm in book.names:
            try:
                name = nm.name
                refers_to = nm.refers_to  # e.g., ="'Sheet'!$A$1:$B$2"
            except Exception:
                # Skip names we cannot read (rare)
                continue
            sheet = parse_sheet_from_refers_to(refers_to)
            if not name or not refers_to:
                continue
            w.writerow([sheet, name, refers_to])
            count += 1
    return count


def main() -> None:
    if not INPUT_PATH.exists():
        raise FileNotFoundError(f"Excel input not found: {INPUT_PATH.resolve()}")

    app: Optional[xw.App] = None
    book: Optional[xw.Book] = None
    try:
        app = xw.App(visible=False, add_book=False)
        app.display_alerts = False
        app.screen_updating = False

        book = app.books.open(str(INPUT_PATH), update_links=False, read_only=True)

        cell_rows = export_cells(book)
        range_rows = export_named_ranges(book)

        # Basic sanity output for humans
        print(f"Wrote {OUT_CELLS} with {cell_rows} data rows.")
        print(f"Wrote {OUT_RANGES} with {range_rows} data rows.")
        print(f"Workbook: {INPUT_PATH}")

    finally:
        try:
            if book is not None:
                book.close()
        finally:
            if app is not None:
                app.quit()


if __name__ == "__main__":
    main()

Du:
## TASK 2 – Implement Code for VBA Export (VBA → TXT)

1. **Goal**: Create a simple script to tranlsate Excel-VBA-Module-Content in text (`vba_to_text.py`)
2. **Input for the script**: `Tariff_Calculator.xlsm`  
3. **Output fo the script**: One `Mod_*.txt` file per VBA module  
4. **Procedure for the script**  
   - Use `oletools.olevba` or `vb2py` to dump the modules.  
   - Filename scheme: `Mod_<Name>.txt`.  
   - Process all non‑empty code modules, including those without `Sub` (e. g., with constants).    
   - Ignore empty modules or code objects (e. g., Excel worksheet without code).  
5. **Success Check**  
   - Number of `.txt` files ≥ number of non‑empty modules in the VBA editor.  
   - Each file contains at least one `Sub` or `Function`.

ChatGPT:
#!/usr/bin/env python3
"""
VBA_TO_TEXT: Export all non-empty VBA modules from an .xlsm into text files.

Input:
  input/Tariff_Calculator.xlsm

Output (written to project root / current working directory):
  - Mod_<Name>.txt for each non-empty VBA code module

Rules implemented:
  - Uses oletools.olevba to extract modules.
  - Writes one file per module (deduplicates by output filename).
  - Ignores empty modules / code objects with no code text.
  - Includes modules even if they only contain constants (no Sub/Function).
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Dict

from oletools.olevba import VBA_Parser  # type: ignore


INPUT_PATH = Path("input") / "Tariff_Calculator.xlsm"
OUT_PREFIX = "Mod_"

INVALID_FILENAME_CHARS = re.compile(r'[<>:"/\\|?*\x00-\x1F]+')
SUBFUNC_RE = re.compile(r"(?im)^\s*(public|private|friend)?\s*(sub|function)\b")


def sanitize_filename(name: str) -> str:
    name = (name or "").strip()
    name = INVALID_FILENAME_CHARS.sub("_", name)
    name = re.sub(r"\s+", "_", name)
    name = name.strip("._")
    return name or "Unnamed"


def normalize_newlines(text: str) -> str:
    return text.replace("\r\n", "\n").replace("\r", "\n")


def pick_module_name(vba_filename: str, stream_path: str) -> str:
    name = (vba_filename or "").strip()
    if name:
        return name
    parts = (stream_path or "").replace("\\", "/").split("/")
    return parts[-1] if parts and parts[-1] else "Unnamed"


def unique_path(base: Path, used: set[str]) -> Path:
    """Ensure filename uniqueness within this run."""
    if base.name not in used:
        used.add(base.name)
        return base
    stem, suffix = base.stem, base.suffix
    i = 2
    while True:
        candidate = base.with_name(f"{stem}_{i}{suffix}")
        if candidate.name not in used:
            used.add(candidate.name)
            return candidate
        i += 1


def main() -> None:
    if not INPUT_PATH.exists():
        raise FileNotFoundError(f"Excel input not found: {INPUT_PATH.resolve()}")

    out_dir = Path(".")
    used_filenames: set[str] = set()
    written: Dict[str, Path] = {}
    exported_count = 0
    skipped_empty = 0
    no_subfunc_count = 0

    vba = VBA_Parser(str(INPUT_PATH))
    try:
        if not vba.detect_vba_macros():
            print("No VBA macros detected.")
            return

        for (_container, stream_path, vba_filename, code) in vba.extract_macros():
            if code is None:
                skipped_empty += 1
                continue

            code_text = normalize_newlines(str(code)).strip()
            if not code_text:
                skipped_empty += 1
                continue

            module_name = pick_module_name(str(vba_filename or ""), str(stream_path or ""))
            safe_name = sanitize_filename(module_name)

            base_path = out_dir / f"{OUT_PREFIX}{safe_name}.txt"
            out_path = unique_path(base_path, used_filenames)

            out_path.write_text(code_text + "\n", encoding="utf-8")
            written[module_name] = out_path
            exported_count += 1

            if not SUBFUNC_RE.search(code_text):
                no_subfunc_count += 1
                print(
                    f"Warning: exported module '{module_name}' but it contains no Sub/Function."
                )

    finally:
        # oletools versions differ; close() exists on newer versions
        close = getattr(vba, "close", None)
        if callable(close):
            close()

    print(f"Exported {exported_count} non-empty VBA modules to Mod_*.txt")
    print(f"Skipped {skipped_empty} empty code objects/modules.")
    if exported_count:
        print(f"Modules without Sub/Function: {no_subfunc_count}")


if __name__ == "__main__":
    main()

Du:
## TASK 3 – Implement Code to Extract Data from Excel via earlier produced .csv files

1. **Goal**: Create a simple script to create the extract of the relevant data (data_extract.py)
2. **Input for the script**: CSV files excelcell.csv, excelrange.csv (uploaded to LLM)  
3. **Output fo the script**  
   - var.csv  – Variables (sheet *Calculation*, A4:B9), contract‑specific  
   - tariff.csv – Tariff data (sheet *Calculation*, D4:E11), shared across multiple contracts  
   - limits.csv – Limits (sheet *Calculation*, G4:H5)  
   - tables.csv – MortalityTable (sheet *MortalityTables*, columns A–E, data starting in row 4, headers in row 3)  
   - tariff.py  – function **ModalSurcharge(PayFreq)** (Excel formula E12)  
4. **Procedure for the script**  
   - Read each listed cell block from the input files.  
   - Write CSVs exactly in the specified column formats.  
   - For CSVs, always include one column *Name* and one column *Value*.  
   - Implement ModalSurcharge(PayFreq) exactly according to the formula in cell E12.  
5. **Success Check**  
   - All files exist & have ≥ 1 data row (tables ≥ 100).  
   - import tariff; tariff.ModalSurcharge(12) returns the same value as Excel cell E12.

ChatGPT:

Nachgedacht für 48s
#!/usr/bin/env python3
"""
DATA_EXTRACT: Create normalized input datasets from excel exports.

Inputs (expected in project root):
  - excelcell.csv   columns: Sheet, Address, Formula, Value
  - excelrange.csv  columns: Sheet, Name, Address   (not required for the specific outputs, but validated)

If not found in CWD, the script also checks:
  - /mnt/data/excelcell.csv
  - /mnt/data/excelrange.csv

Outputs (written to project root / current working directory):
  - var.csv     (Name, Value) from Calculation!A4:B9
  - tariff.csv  (Name, Value) from Calculation!D4:E11
  - limits.csv  (Name, Value) from Calculation!G4:H5
  - tables.csv  (Name, Value) from MortalityTables!A:E (headers row 3, data from row 4)
  - tariff.py   implements ModalSurcharge(PayFreq) exactly per Calculation!E12

Success intent:
  - All files exist & have >= 1 data row (tables >= 100 expected for this workbook)
  - import tariff; tariff.ModalSurcharge(12) matches the Excel E12 logic.
"""

from __future__ import annotations

import csv
import json
import re
from pathlib import Path
from typing import Dict, List, Tuple

# ----------------------------
# Paths
# ----------------------------
CANDIDATE_EXCELCELL = [Path("excelcell.csv"), Path("/mnt/data/excelcell.csv")]
CANDIDATE_EXCELRANGE = [Path("excelrange.csv"), Path("/mnt/data/excelrange.csv")]

OUT_VAR = Path("var.csv")
OUT_TARIFF = Path("tariff.csv")
OUT_LIMITS = Path("limits.csv")
OUT_TABLES = Path("tables.csv")
OUT_TARIFF_PY = Path("tariff.py")

A1_RE = re.compile(r"^\$?([A-Z]+)\$?(\d+)$", re.IGNORECASE)


def pick_existing(candidates: List[Path]) -> Path:
    for p in candidates:
        if p.exists():
            return p
    raise FileNotFoundError(f"None of these input files exist: {', '.join(map(str, candidates))}")


# ----------------------------
# A1 helpers
# ----------------------------
def col_letters_to_num(letters: str) -> int:
    letters = letters.strip().upper()
    n = 0
    for ch in letters:
        if not ("A" <= ch <= "Z"):
            raise ValueError(f"Invalid column letters: {letters}")
        n = n * 26 + (ord(ch) - ord("A") + 1)
    return n


def col_num_to_letters(n: int) -> str:
    if n < 1:
        raise ValueError(f"Invalid column number: {n}")
    out = []
    while n:
        n, rem = divmod(n - 1, 26)
        out.append(chr(ord("A") + rem))
    return "".join(reversed(out))


def a1(row: int, col: int) -> str:
    return f"{col_num_to_letters(col)}{row}"


# ----------------------------
# Load excelcell.csv into mapping
# ----------------------------
def load_excelcell(path: Path) -> Dict[Tuple[str, str], Dict[str, str]]:
    """
    Mapping:
      (sheet, address_upper) -> {"value": str, "formula": str}
    """
    out: Dict[Tuple[str, str], Dict[str, str]] = {}
    with path.open("r", encoding="utf-8-sig", newline="") as f:
        r = csv.DictReader(f)
        required = {"Sheet", "Address", "Formula", "Value"}
        if not r.fieldnames or not required.issubset(set(r.fieldnames)):
            raise ValueError(f"{path} must have columns {sorted(required)}; got {r.fieldnames}")

        for row in r:
            sheet = (row.get("Sheet") or "").strip()
            addr = (row.get("Address") or "").strip().upper()
            if not sheet or not addr:
                continue
            out[(sheet, addr)] = {
                "value": row.get("Value") or "",
                "formula": row.get("Formula") or "",
            }
    return out


def validate_excelrange(path: Path) -> None:
    with path.open("r", encoding="utf-8-sig", newline="") as f:
        r = csv.DictReader(f)
        required = {"Sheet", "Name", "Address"}
        if not r.fieldnames or not required.issubset(set(r.fieldnames)):
            raise ValueError(f"{path} must have columns {sorted(required)}; got {r.fieldnames}")


def get_value(cells: Dict[Tuple[str, str], Dict[str, str]], sheet: str, addr: str) -> str:
    rec = cells.get((sheet, addr.upper()))
    return "" if rec is None else (rec.get("value") or "")


def get_formula(cells: Dict[Tuple[str, str], Dict[str, str]], sheet: str, addr: str) -> str:
    rec = cells.get((sheet, addr.upper()))
    return "" if rec is None else (rec.get("formula") or "")


# ----------------------------
# Block extraction helpers
# ----------------------------
def write_name_value(path: Path, rows: List[Tuple[str, str]]) -> None:
    with path.open("w", encoding="utf-8", newline="") as f:
        w = csv.writer(f)
        w.writerow(["Name", "Value"])
        for name, value in rows:
            name_s = (name or "").strip()
            value_s = (value or "").strip()
            if name_s == "" and value_s == "":
                continue
            w.writerow([name_s, value_s])


def extract_two_col_rows(
    cells: Dict[Tuple[str, str], Dict[str, str]],
    sheet: str,
    name_col: str,
    value_col: str,
    row_start: int,
    row_end: int,
) -> List[Tuple[str, str]]:
    nc = col_letters_to_num(name_col)
    vc = col_letters_to_num(value_col)
    out: List[Tuple[str, str]] = []
    for r in range(row_start, row_end + 1):
        name = get_value(cells, sheet, a1(r, nc))
        value = get_value(cells, sheet, a1(r, vc))
        if (name or "").strip() == "" and (value or "").strip() == "":
            continue
        out.append((name, value))
    return out


# ----------------------------
# MortalityTables extraction
# ----------------------------
def parse_row_col(addr: str) -> Tuple[int, int]:
    m = A1_RE.match(addr.strip().upper())
    if not m:
        raise ValueError(f"Bad A1: {addr}")
    col = col_letters_to_num(m.group(1))
    row = int(m.group(2))
    return row, col


def extract_mortality_tables(
    cells: Dict[Tuple[str, str], Dict[str, str]],
    sheet: str = "MortalityTables",
    header_row: int = 3,
    data_row_start: int = 4,
    col_start: str = "A",
    col_end: str = "E",
) -> List[Tuple[str, str]]:
    c1 = col_letters_to_num(col_start)
    c2 = col_letters_to_num(col_end)

    # headers from row 3
    headers: List[str] = []
    for c in range(c1, c2 + 1):
        h = (get_value(cells, sheet, a1(header_row, c)) or "").strip()
        headers.append(h if h else f"Col{col_num_to_letters(c)}")

    # find max data row that has any non-empty value within A:E
    max_row = 0
    for (sh, addr), rec in cells.items():
        if sh != sheet:
            continue
        try:
            r, c = parse_row_col(addr)
        except ValueError:
            continue
        if r < data_row_start or not (c1 <= c <= c2):
            continue
        v = (rec.get("value") or "").strip()
        f = (rec.get("formula") or "").strip()
        if v != "" or f != "":
            max_row = max(max_row, r)

    if max_row < data_row_start:
        return []

    out: List[Tuple[str, str]] = []
    for r in range(data_row_start, max_row + 1):
        row_dict: Dict[str, str] = {}
        any_nonempty = False
        first_val = ""
        for i, c in enumerate(range(c1, c2 + 1)):
            v = (get_value(cells, sheet, a1(r, c)) or "").strip()
            row_dict[headers[i]] = v
            if i == 0:
                first_val = v
            if v != "":
                any_nonempty = True

        if not any_nonempty:
            continue

        # Stable row key: include first column value if present, else row number
        key = first_val if first_val else f"ROW{r}"
        name = f"{key}|{r}"
        value = json.dumps(row_dict, ensure_ascii=False)
        out.append((name, value))

    return out


# ----------------------------
# ModalSurcharge extraction & codegen
# ----------------------------
E12_PATTERN = re.compile(
    r"""^=IF\s*\(\s*PayFreq\s*=\s*(\d+)\s*,\s*([\d.]+)%\s*,\s*IF\s*\(\s*PayFreq\s*=\s*(\d+)\s*,\s*([\d.]+)%\s*,\s*IF\s*\(\s*PayFreq\s*=\s*(\d+)\s*,\s*([\d.]+)%\s*,\s*0\s*\)\s*\)\s*\)\s*$""",
    re.IGNORECASE,
)


def render_tariff_py_from_e12(e12_formula: str) -> str:
    """
    Exact implementation for this workbook's E12 formula:
      =IF(PayFreq=2,2%,IF(PayFreq=4,3%,IF(PayFreq=12,5%,0)))
    We generate code directly from the formula, and validate it matches this pattern.
    """
    f = (e12_formula or "").strip()
    if not f:
        raise ValueError("Missing E12 formula text.")

    m = E12_PATTERN.match(f.replace(" ", ""))
    if not m:
        # Fallback: keep formula as comment and implement the known behavior only if it matches expected set.
        # But we fail hard to avoid silent mismatches.
        raise ValueError(f"Unexpected E12 formula format: {f!r}")

    pf1, p1, pf2, p2, pf3, p3 = m.groups()
    mapping = {
        int(pf1): float(p1) / 100.0,
        int(pf2): float(p2) / 100.0,
        int(pf3): float(p3) / 100.0,
    }

    return f'''"""
Auto-generated by data_extract.py from excelcell.csv.

Implements ModalSurcharge(PayFreq) exactly as the Excel formula in Calculation!E12:
  {f}
"""

from __future__ import annotations


EXCEL_E12_FORMULA = {f!r}
_MODAL_MAP = {mapping!r}


def ModalSurcharge(PayFreq: int) -> float:
    """
    Modal surcharge for payment frequency.

    Mirrors the nested IF in Excel cell Calculation!E12.
    """
    try:
        pf = int(PayFreq)
    except Exception as e:
        raise TypeError("PayFreq must be convertible to int") from e
    return float(_MODAL_MAP.get(pf, 0.0))
'''


# ----------------------------
# Main
# ----------------------------
def main() -> None:
    excelcell = pick_existing(CANDIDATE_EXCELCELL)
    excelrange = pick_existing(CANDIDATE_EXCELRANGE)

    validate_excelrange(excelrange)
    cells = load_excelcell(excelcell)

    # var.csv: Calculation A4:B9
    var_rows = extract_two_col_rows(cells, "Calculation", "A", "B", 4, 9)
    write_name_value(OUT_VAR, var_rows)

    # tariff.csv: Calculation D4:E11
    tariff_rows = extract_two_col_rows(cells, "Calculation", "D", "E", 4, 11)
    write_name_value(OUT_TARIFF, tariff_rows)

    # limits.csv: Calculation G4:H5
    limits_rows = extract_two_col_rows(cells, "Calculation", "G", "H", 4, 5)
    write_name_value(OUT_LIMITS, limits_rows)

    # tables.csv: MortalityTables A:E, headers row 3, data from row 4
    tables_rows = extract_mortality_tables(cells)
    write_name_value(OUT_TABLES, tables_rows)

    # tariff.py: ModalSurcharge(PayFreq) from Calculation!E12 formula
    e12_formula = get_formula(cells, "Calculation", "E12")
    if not e12_formula.strip():
        raise ValueError("Could not find Calculation!E12 formula in excelcell.csv (missing or empty Formula column).")
    OUT_TARIFF_PY.write_text(render_tariff_py_from_e12(e12_formula), encoding="utf-8")

    # Minimal runtime checks (non-fatal prints)
    def data_rows(p: Path) -> int:
        with p.open("r", encoding="utf-8-sig", newline="") as f:
            return max(0, sum(1 for _ in f) - 1)

    print(f"Inputs: {excelcell} , {excelrange}")
    print(f"Wrote {OUT_VAR} rows={data_rows(OUT_VAR)}")
    print(f"Wrote {OUT_TARIFF} rows={data_rows(OUT_TARIFF)}")
    print(f"Wrote {OUT_LIMITS} rows={data_rows(OUT_LIMITS)}")
    print(f"Wrote {OUT_TABLES} rows={data_rows(OUT_TABLES)}")
    print(f"Wrote {OUT_TARIFF_PY} (ModalSurcharge from Calculation!E12)")


if __name__ == "__main__":
    main()

Du:
## TASK 4 – Implement Code to Generate Test Fixtures

1. **Goal**: Creat tests (tests/conftest.py, tests/test_data_roundtrip.py)
2. **Input for LLM**: Existing CSV files (var.csv, tariff.csv, tariff.py, limits.csv, tables.csv)  
3. **Input for the script**: Existing CSV files (var.csv, tariff.csv, tariff.py, limits.csv, tables.csv)  
4. **Output**: Folder tests/ with pytest fixtures  
5. **Procedure**  
   - LLM create two code blocks
   - conftest.py sets up temp directory & mini CSV samples.  
   - Create smoke test test_data_roundtrip.py that reads each CSV and counts columns.  
6. **Success Check**  
   - pytest -q runs green (0 errors, 0 failures).

ChatGPT:
# tests/conftest.py
from __future__ import annotations

import csv
import shutil
from pathlib import Path

import pytest

PROJECT_ROOT = Path(__file__).resolve().parents[1]
FALLBACK_DIR = Path("/mnt/data")


def _source_file(name: str) -> Path:
    """Prefer project root, fall back to /mnt/data (used by some LLM environments)."""
    p = PROJECT_ROOT / name
    if p.exists():
        return p
    p2 = FALLBACK_DIR / name
    if p2.exists():
        return p2
    raise FileNotFoundError(f"Required input file not found in project root or /mnt/data: {name}")


def _mini_csv(src: Path, dst: Path, max_rows: int) -> None:
    """Copy CSV with header + up to max_rows data rows."""
    with src.open("r", encoding="utf-8-sig", newline="") as fin:
        reader = csv.reader(fin)
        try:
            header = next(reader)
        except StopIteration as e:
            raise ValueError(f"CSV has no header: {src}") from e

        rows = [header]
        for i, row in enumerate(reader):
            if i >= max_rows:
                break
            rows.append(row)

    with dst.open("w", encoding="utf-8", newline="") as fout:
        writer = csv.writer(fout)
        writer.writerows(rows)


@pytest.fixture()
def data_dir(tmp_path: Path) -> Path:
    """
    Temp dir containing small, deterministic samples of the product data.
    """
    mini_specs = {
        "var.csv": 50,
        "tariff.csv": 50,
        "limits.csv": 50,
        "tables.csv": 200,
    }

    for filename, max_rows in mini_specs.items():
        src = _source_file(filename)
        _mini_csv(src, tmp_path / filename, max_rows=max_rows)

    shutil.copyfile(_source_file("tariff.py"), tmp_path / "tariff.py")
    return tmp_path
# tests/test_data_roundtrip.py
from __future__ import annotations

import csv
import importlib.util
from pathlib import Path


def _read_header(path: Path) -> list[str]:
    with path.open("r", encoding="utf-8-sig", newline="") as f:
        r = csv.reader(f)
        try:
            return next(r)
        except StopIteration:
            return []


def _count_rows(path: Path) -> int:
    with path.open("r", encoding="utf-8-sig", newline="") as f:
        r = csv.reader(f)
        try:
            next(r)  # header
        except StopIteration:
            return 0
        return sum(1 for _ in r)


def test_csv_roundtrip_smoke(data_dir: Path) -> None:
    for filename in ("var.csv", "tariff.csv", "limits.csv", "tables.csv"):
        p = data_dir / filename
        assert p.exists(), f"Missing file: {p}"

        header = _read_header(p)
        assert header, f"{filename}: missing header row"
        assert "Name" in header and "Value" in header, f"{filename}: expected Name/Value columns, got {header}"
        assert len(header) >= 2, f"{filename}: expected >=2 columns, got {len(header)}"

        assert _count_rows(p) >= 1, f"{filename}: expected at least 1 data row"

    # tables.csv should be non-trivial even in mini sample
    assert _count_rows(data_dir / "tables.csv") >= 10


def test_tariff_module_import_and_modal_surcharge(data_dir: Path) -> None:
    tariff_path = data_dir / "tariff.py"
    assert tariff_path.exists()

    spec = importlib.util.spec_from_file_location("tariff_testcopy", str(tariff_path))
    assert spec is not None and spec.loader is not None
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)  # type: ignore[attr-defined]

    assert hasattr(mod, "ModalSurcharge")
    v = mod.ModalSurcharge(12)
    assert isinstance(v, float)

Du:
## TASK 5A – Implement Code to Translate Base Functions

1. **Goal**: Translate VBA code into python
2. **Input for LLM**: All Mod_*.txt from TASK 2  
3. **Output of LLM**: basfunct.py  
4. **Procedure**  
   - Each VBA Function/Procedure is mapped 1‑to‑1 to a Python def.  
   - Use pandas for table/CSV access.  
   - No function body may end with pass.  
   - Available data sources for the python script: excelcell.csv, excelrange.csv, var.csv, tariff.csv, limits.csv, tables.csv.


ChatGPT:
# basfunct.py
"""
BASISFUNCT – 1-to-1 port of VBA base functions to Python.

Source VBA modules:
- Mod_mPresentValues.txt
- Mod_mCommValues.txt
- Mod_mConstants.txt

Data sources (CSV):
- tables.csv (MortalityTables) is used for Act_qx / commutation functions.

Notes:
- Uses pandas for CSV access.
- Caching mirrors VBA's Scripting.Dictionary usage.
- Excel/VBA rounding differs from Python's bankers rounding; we implement Excel-like ROUND.
- Fix: avoids deprecated pd.to_numeric(errors="ignore") to silence FutureWarning.
"""

from __future__ import annotations

import json
import math
from dataclasses import dataclass
from datetime import date, datetime
from pathlib import Path
from typing import Any, Dict, Optional

import pandas as pd

# ----------------------------
# Constants (from mConstants)
# ----------------------------
round_lx: int = 16
round_tx: int = 16
round_Dx: int = 16
round_Cx: int = 16
round_Nx: int = 16
round_Mx: int = 16
round_Rx: int = 16
max_Age: int = 123


# ----------------------------
# Data access
# ----------------------------
@dataclass
class DataRepo:
    root: Path = Path.cwd()
    _cache: Dict[str, pd.DataFrame] = None  # type: ignore[assignment]

    def __post_init__(self) -> None:
        if self._cache is None:
            self._cache = {}

    def _path(self, name: str) -> Path:
        p = self.root / name
        if p.exists():
            return p
        p2 = Path("/mnt/data") / name
        if p2.exists():
            return p2
        raise FileNotFoundError(f"Missing data source: {name}")

    def read_csv(self, name: str) -> pd.DataFrame:
        if name not in self._cache:
            self._cache[name] = pd.read_csv(self._path(name), encoding="utf-8")
        return self._cache[name]

    @staticmethod
    def _safe_numeric_coerce(series: pd.Series) -> pd.Series:
        """
        Convert string-like series to numeric where possible.
        - Empty strings / 'nan' / 'None' become NaN.
        - Values that cannot be converted remain as their original (string) value.
        This avoids deprecated `errors="ignore"` behavior while preserving non-numeric text.
        """
        if series.dtype != object:
            return series

        s_str = series.astype(str)
        empties = s_str.str.strip().isin(["", "nan", "None"])
        s_clean = s_str.where(~empties, None)

        numeric = pd.to_numeric(s_clean, errors="coerce")
        # Keep original where conversion failed but original wasn't empty
        failed = numeric.isna() & ~empties

        # If nothing failed, return numeric
        if not failed.any():
            return numeric

        # Mixed: preserve originals for failed values, numeric for successful values
        out = series.copy()
        out.loc[~failed] = numeric.loc[~failed]
        return out

    def mortality_tables_df(self) -> pd.DataFrame:
        """
        Build a DataFrame from tables.csv (Name, Value where Value is JSON per row).
        Expected JSON keys correspond to MortalityTables headers.
        """
        df = self.read_csv("tables.csv")
        if "Value" not in df.columns:
            raise ValueError("tables.csv must have column 'Value'")

        rows = []
        for v in df["Value"].astype(str):
            try:
                rows.append(json.loads(v))
            except json.JSONDecodeError:
                # allow already-plain rows (shouldn't happen)
                rows.append({"_raw": v})

        tdf = pd.DataFrame(rows)

        # Coerce numeric columns safely (no FutureWarning)
        for c in tdf.columns:
            tdf[c] = self._safe_numeric_coerce(tdf[c])

        return tdf


_DATA = DataRepo()


# ----------------------------
# Excel-like rounding helpers
# ----------------------------
def _excel_round(x: float, digits: int = 0) -> float:
    """
    Excel/VBA WorksheetFunction.Round: halves away from zero.
    Python round() is bankers rounding; do NOT use it here.
    """
    if digits >= 0:
        factor = 10.0**digits
        return math.copysign(math.floor(abs(x) * factor + 0.5) / factor, x)
    factor = 10.0 ** (-digits)
    return math.copysign(math.floor(abs(x) / factor + 0.5) * factor, x)


# ----------------------------
# Cache (from mCommValues)
# ----------------------------
cache: Optional[Dict[str, float]] = None


def InitializeCache() -> None:
    """Create a new Dictionary object (Python dict)."""
    global cache
    cache = {}


# ----------------------------
# Mortality / commutation functions (from mCommValues)
# ----------------------------
def Act_qx(
    Age: int,
    Sex: str,
    TableId: str,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    """
    Equivalent to VBA:
      Select Case TableId: "DAV1994_T", "DAV2008_T"
      tableVector = UCase(TableId) & "_" & Sex
      Index(m_Tables, Age+1, Match(tableVector, v_Tables, 0))
    """
    sex = (Sex or "").upper()
    if sex != "M":
        sex = "F"

    table_id = (TableId or "").upper()
    if table_id not in ("DAV1994_T", "DAV2008_T"):
        raise ValueError(f"Unsupported TableId: {TableId}")

    table_vector = f"{table_id}_{sex}"

    tdf = _DATA.mortality_tables_df()

    # Find an "Age" column (common), otherwise assume the first column is age-like.
    age_col = None
    for cand in ("Age", "AGE", "alter", "ALTER"):
        if cand in tdf.columns:
            age_col = cand
            break

    if table_vector not in tdf.columns:
        raise KeyError(f"Column '{table_vector}' not found in tables.csv-derived DataFrame")

    if age_col is not None:
        match = tdf.loc[tdf[age_col] == Age, table_vector]
        if match.empty:
            # fallback: treat row index as age (0-based)
            if 0 <= Age < len(tdf):
                return float(tdf.iloc[Age][table_vector])
            raise IndexError(f"Age {Age} not found in Age column and out of bounds.")
        return float(match.iloc[0])

    # No age column: assume 0-based row corresponds to Age=0
    if 0 <= Age < len(tdf):
        return float(tdf.iloc[Age][table_vector])
    raise IndexError(f"Age {Age} out of bounds for tables data (len={len(tdf)}).")


def Vec_lx(
    EndAge: int,
    Sex: str,
    TableId: str,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of lx; if EndAge = -1 then it is created up to max_Age."""
    limit = max_Age if EndAge == -1 else EndAge
    vec: list[float] = [0.0] * (limit + 1)
    vec[0] = 1_000_000.0
    for i in range(1, limit + 1):
        vec[i] = vec[i - 1] * (1.0 - Act_qx(i - 1, Sex, TableId, BirthYear, RetirementAge, Layer))
        vec[i] = float(_excel_round(vec[i], round_lx))
    return vec


def Act_lx(
    Age: int,
    Sex: str,
    TableId: str,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    vec = Vec_lx(Age, Sex, TableId, BirthYear, RetirementAge, Layer)
    return float(vec[Age])


def Vec_tx(
    EndAge: int,
    Sex: str,
    TableId: str,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of tx (# deaths)."""
    limit = max_Age if EndAge == -1 else EndAge
    vec: list[float] = [0.0] * (limit + 1)
    temp_lx = Vec_lx(limit, Sex, TableId, BirthYear, RetirementAge, Layer)
    for i in range(0, limit):
        vec[i] = temp_lx[i] - temp_lx[i + 1]
        vec[i] = float(_excel_round(vec[i], round_tx))
    return vec


def Act_tx(
    Age: int,
    Sex: str,
    TableId: str,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    vec = Vec_tx(Age, Sex, TableId, BirthYear, RetirementAge, Layer)
    return float(vec[Age])


def Vec_Dx(
    EndAge: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of Dx."""
    limit = max_Age if EndAge == -1 else EndAge
    vec: list[float] = [0.0] * (limit + 1)
    v = 1.0 / (1.0 + float(InterestRate))
    temp_lx = Vec_lx(limit, Sex, TableId, BirthYear, RetirementAge, Layer)
    for i in range(0, limit + 1):
        vec[i] = temp_lx[i] * (v**i)
        vec[i] = float(_excel_round(vec[i], round_Dx))
    return vec


def BuildCacheKey(
    Kind: str,
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int,
    RetirementAge: int,
    Layer: int,
) -> str:
    return f"{Kind}_{Age}_{Sex}_{TableId}_{InterestRate}_{BirthYear}_{RetirementAge}_{Layer}"


def Act_Dx(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    global cache
    if cache is None:
        InitializeCache()
    assert cache is not None

    key = BuildCacheKey("Dx", Age, Sex, TableId, float(InterestRate), int(BirthYear), int(RetirementAge), int(Layer))
    if key in cache:
        return float(cache[key])

    vec = Vec_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    val = float(vec[Age])
    cache[key] = val
    return val


def Vec_Cx(
    EndAge: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of Cx."""
    limit = max_Age if EndAge == -1 else EndAge
    vec: list[float] = [0.0] * (limit + 1)
    v = 1.0 / (1.0 + float(InterestRate))
    temp_tx = Vec_tx(limit, Sex, TableId, BirthYear, RetirementAge, Layer)
    for i in range(0, limit):
        vec[i] = temp_tx[i] * (v ** (i + 1))
        vec[i] = float(_excel_round(vec[i], round_Cx))
    return vec


def Act_Cx(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    global cache
    if cache is None:
        InitializeCache()
    assert cache is not None

    key = BuildCacheKey("Cx", Age, Sex, TableId, float(InterestRate), int(BirthYear), int(RetirementAge), int(Layer))
    if key in cache:
        return float(cache[key])

    vec = Vec_Cx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    val = float(vec[Age])
    cache[key] = val
    return val


def Vec_Nx(
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of Nx."""
    vec: list[float] = [0.0] * (max_Age + 1)
    temp_dx = Vec_Dx(-1, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    vec[max_Age] = temp_dx[max_Age]
    for i in range(max_Age - 1, -1, -1):
        vec[i] = vec[i + 1] + temp_dx[i]
        vec[i] = float(_excel_round(vec[i], round_Dx))  # kept as in original
    return vec


def Act_Nx(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    global cache
    if cache is None:
        InitializeCache()
    assert cache is not None

    key = BuildCacheKey("Nx", Age, Sex, TableId, float(InterestRate), int(BirthYear), int(RetirementAge), int(Layer))
    if key in cache:
        return float(cache[key])

    vec = Vec_Nx(Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    val = float(vec[Age])
    cache[key] = val
    return val


def Vec_Mx(
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of Mx."""
    vec: list[float] = [0.0] * (max_Age + 1)
    temp_cx = Vec_Cx(-1, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    vec[max_Age] = temp_cx[max_Age]
    for i in range(max_Age - 1, -1, -1):
        vec[i] = vec[i + 1] + temp_cx[i]
        vec[i] = float(_excel_round(vec[i], round_Mx))
    return vec


def Act_Mx(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    global cache
    if cache is None:
        InitializeCache()
    assert cache is not None

    key = BuildCacheKey("Mx", Age, Sex, TableId, float(InterestRate), int(BirthYear), int(RetirementAge), int(Layer))
    if key in cache:
        return float(cache[key])

    vec = Vec_Mx(Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    val = float(vec[Age])
    cache[key] = val
    return val


def Vec_Rx(
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> list[float]:
    """Creates vector of Rx."""
    vec: list[float] = [0.0] * (max_Age + 1)
    temp_mx = Vec_Mx(Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    vec[max_Age] = temp_mx[max_Age]
    for i in range(max_Age - 1, -1, -1):
        vec[i] = vec[i + 1] + temp_mx[i]
        vec[i] = float(_excel_round(vec[i], round_Rx))
    return vec


def Act_Rx(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    global cache
    if cache is None:
        InitializeCache()
    assert cache is not None

    key = BuildCacheKey("Rx", Age, Sex, TableId, float(InterestRate), int(BirthYear), int(RetirementAge), int(Layer))
    if key in cache:
        return float(cache[key])

    vec = Vec_Rx(Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    val = float(vec[Age])
    cache[key] = val
    return val


def Act_AgeCalculation(BirthDate: date, ValuationDate: date, Method: str) -> int:
    """Age calculation based on calendar-year method (K) or half-year method (H)."""
    method = Method if Method == "K" else "H"

    # Accept datetime as well
    if isinstance(BirthDate, datetime):
        BirthDate = BirthDate.date()
    if isinstance(ValuationDate, datetime):
        ValuationDate = ValuationDate.date()

    y_birth = BirthDate.year
    y_val = ValuationDate.year
    m_birth = BirthDate.month
    m_val = ValuationDate.month

    if method == "K":
        return int(y_val - y_birth)
    # "H"
    return int(math.floor(y_val - y_birth + (1.0 / 12.0) * (m_val - m_birth + 5)))


# ----------------------------
# Present value functions (from mPresentValues)
# ----------------------------
def Act_DeductionTerm(k: int, InterestRate: float) -> float:
    """Deduction term."""
    acc = 0.0
    if k > 0:
        for l in range(0, k):
            acc += (l / k) / (1.0 + (l / k) * float(InterestRate))
        acc = acc * (1.0 + float(InterestRate)) / k
    return float(acc)


def Act_ax_k(
    Age: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    k: int,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    if k > 0:
        return float(
            Act_Nx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
            / Act_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
            - Act_DeductionTerm(k, float(InterestRate))
        )
    return 0.0


def Act_axn_k(
    Age: int,
    n: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    k: int,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    if k <= 0:
        return 0.0

    nx_age = Act_Nx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    nx_agen = Act_Nx(Age + n, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    dx_age = Act_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    dx_agen = Act_Dx(Age + n, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)

    return float(
        (nx_age - nx_agen) / dx_age
        - Act_DeductionTerm(k, float(InterestRate)) * (1.0 - dx_agen / dx_age)
    )


def Act_nax_k(
    Age: int,
    n: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    k: int,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    if k > 0:
        return float(
            Act_Dx(Age + n, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
            / Act_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
            * Act_ax_k(Age + n, Sex, TableId, float(InterestRate), k, BirthYear, RetirementAge, Layer)
        )
    return 0.0


def act_nGrAx(
    Age: int,
    n: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    return float(
        (
            Act_Mx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
            - Act_Mx(Age + n, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
        )
        / Act_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    )


def act_nGrEx(
    Age: int,
    n: int,
    Sex: str,
    TableId: str,
    InterestRate: float,
    BirthYear: int = 0,
    RetirementAge: int = 0,
    Layer: int = 1,
) -> float:
    return float(
        Act_Dx(Age + n, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
        / Act_Dx(Age, Sex, TableId, float(InterestRate), BirthYear, RetirementAge, Layer)
    )


def Act_ag_k(g: int, InterestRate: float, k: int) -> float:
    v = 1.0 / (1.0 + float(InterestRate))
    if k > 0:
        if float(InterestRate) > 0:
            return float((1.0 - v**g) / (1.0 - v) - Act_DeductionTerm(k, float(InterestRate)) * (1.0 - v**g))
        return float(g)
    return 0.0
Du:
## TASK 5B – Implement Code for Function Parity Test

**Success Check**: LLM creates `tests/test_func_parity.py` that  
- collects all **public** VBA names (`Function`/`Sub` without `Private`),  
- scans Python `def` names in `basfunct.py` (helpers may be ignored),  
- and verifies that for each VBA name exactly one Python function exists.  
Passing = `pytest -q` runs completely green.

ChatGPT:
# tests/test_func_parity.py
from __future__ import annotations

import ast
import re
from pathlib import Path
from typing import Iterable, Set

# VBA: Public if not explicitly Private
VBA_DECL_RE = re.compile(
    r"(?im)^\s*(?:(public|private|friend)\s+)?(function|sub)\s+([A-Za-z_][A-Za-z0-9_]*)\b"
)

# Some VBA members we intentionally ignore (e.g., worksheet event stubs, if any appear)
VBA_IGNORE_NAMES: Set[str] = {
    # add known non-base / event handlers here if they appear in Mod_*.txt
}

# Python helpers inside basfunct.py we don't want to treat as "ported VBA names"
PY_IGNORE_NAMES: Set[str] = {
    "DataRepo",
    "_excel_round",
}


def _find_module_txt_files() -> list[Path]:
    # Prefer project root, but support /mnt/data (LLM sandbox)
    roots = [Path.cwd(), Path("/mnt/data")]
    files: list[Path] = []
    for root in roots:
        files.extend(sorted(root.glob("Mod_*.txt")))
    # de-dupe by resolved path string
    uniq: dict[str, Path] = {}
    for p in files:
        try:
            uniq[str(p.resolve())] = p
        except Exception:
            uniq[str(p)] = p
    return list(uniq.values())


def _vba_public_names_from_text(text: str) -> Set[str]:
    names: Set[str] = set()
    for m in VBA_DECL_RE.finditer(text):
        vis = (m.group(1) or "").strip().lower()
        kind = (m.group(2) or "").strip().lower()
        name = (m.group(3) or "").strip()

        # Only Functions/Subs
        if kind not in ("function", "sub"):
            continue

        # Exclude Private
        if vis == "private":
            continue

        if name in VBA_IGNORE_NAMES:
            continue

        names.add(name)
    return names


def _collect_vba_public_names() -> Set[str]:
    mod_files = _find_module_txt_files()
    assert mod_files, "No Mod_*.txt files found (run TASK 2 VBA export)."

    names: Set[str] = set()
    for p in mod_files:
        text = p.read_text(encoding="utf-8", errors="ignore")
        names |= _vba_public_names_from_text(text)
    assert names, "No public VBA Function/Sub names found in Mod_*.txt files."
    return names


def _collect_python_def_names(basfunct_path: Path) -> Set[str]:
    src = basfunct_path.read_text(encoding="utf-8")
    tree = ast.parse(src, filename=str(basfunct_path))
    names: Set[str] = set()
    for node in tree.body:
        if isinstance(node, ast.FunctionDef):
            if node.name in PY_IGNORE_NAMES:
                continue
            if node.name.startswith("_"):
                continue
            names.add(node.name)
    return names


def test_public_vba_names_have_python_defs() -> None:
    vba_names = _collect_vba_public_names()

    # Locate basfunct.py in project root (or /mnt/data fallback)
    basfunct_candidates = [Path.cwd() / "basfunct.py", Path("/mnt/data") / "basfunct.py"]
    basfunct_path = next((p for p in basfunct_candidates if p.exists()), None)
    assert basfunct_path is not None, "basfunct.py not found (create it in TASK 5A)."

    py_names = _collect_python_def_names(basfunct_path)

    missing = sorted(n for n in vba_names if n not in py_names)
    assert not missing, f"Missing Python defs for VBA public names: {missing}"


def test_no_duplicate_python_defs_for_vba_names() -> None:
    """
    Ensures each VBA public name maps to exactly one Python def.
    (In Python, duplicate def names in the same module would overwrite; we detect that by AST only
    yielding final name set. So we do a stricter check by scanning raw text for 'def <name>(' counts.)
    """
    vba_names = _collect_vba_public_names()

    basfunct_candidates = [Path.cwd() / "basfunct.py", Path("/mnt/data") / "basfunct.py"]
    basfunct_path = next((p for p in basfunct_candidates if p.exists()), None)
    assert basfunct_path is not None, "basfunct.py not found (create it in TASK 5A)."

    src = basfunct_path.read_text(encoding="utf-8")

    duplicates = []
    for name in sorted(vba_names):
        # exact 'def Name(' occurrences
        cnt = len(re.findall(rf"(?m)^\s*def\s+{re.escape(name)}\s*\(", src))
        if cnt != 1:
            duplicates.append((name, cnt))

    assert not duplicates, f"Expected exactly one Python def for each VBA name; mismatches: {duplicates}"
